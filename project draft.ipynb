{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5036,"status":"ok","timestamp":1714605412179,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"0LXrrC_9q3an","outputId":"7aafad20-fbe3-41a6-bc1f-fd2bc68ab753"},"outputs":[],"source":["# Run if using on google collab, change path if using on a copy\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path = '/content/drive/MyDrive/[02] School/[01] University/[02] Bachelor\\'s Year 2/[02] Spring Semester/[04] Machine Learning/Colab Notebooks/ML - LGI/mlproj/'"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# run if running locally\n","path = ''"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30432,"status":"ok","timestamp":1714605442603,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"N5misv8iqv_c","outputId":"5699d9a9-5954-4488-d8c4-c1efca8474bb"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","import multiprocessing\n","\n","cpuc = multiprocessing.cpu_count()-1\n","\n","#setting seaborn visual style in plt\n","sns.set_theme()"]},{"cell_type":"markdown","metadata":{"id":"7rYg5St0J3ap"},"source":["# Integration & Exploration"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["traindata: pd.DataFrame = pd.read_csv(path + 'project_data/train.csv').set_index('Userid')\n","print(f\"Duplicaded: {traindata.duplicated().sum()}\\nMissing: {traindata.isna().sum().sum()}\\nNon-Registered (empty): {(traindata[\"Registered\"] != \"Yes\").sum()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import the data and drop remove useless stuff\n","traindata: pd.DataFrame = traindata.drop('Observations', axis=1).drop_duplicates()\n","testdata: pd.DataFrame = pd.read_csv(path + 'project_data/test.csv').set_index('Userid').drop(['Registered', 'Observations'], axis=1)\n","\n","traindata = traindata[traindata['Registered'] == 'Yes']\n","traindata = traindata.drop('Registered', axis=1)"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1714606527362,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"kGMkB5Dax7jH"},"outputs":[],"source":["metricFeatures: list[str] = ['Application order','Previous qualification score','Entry score','Age at enrollment','N units credited 1st period',\n","       'N units taken 1st period', 'N scored units 1st period',\n","       'N units approved 1st period', 'Average grade 1st period',\n","       'N unscored units 1st period', 'N units credited 2nd period',\n","       'N units taken 2nd period', 'N scored units 2nd period',\n","       'N units approved 2nd period', 'Average grade 2nd period',\n","       'N unscored units 2nd period','Social Popularity']\n","categoricalFeatures: list[str] =  ['Application mode','Marital status','Course','Previous qualification','Nationality',\"Mother's qualification\",\n","       \"Father's qualification\",\"Mother's occupation\",\"Father's occupation\"]\n","boolFeatures: list[str] = ['Morning shift participation','Displaced','Special needs','Debtor','Regularized Fees','Gender_Male','External Funding','International']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["traindata[metricFeatures].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1714615768947,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"0x4hZRPq-PCx"},"outputs":[],"source":["X: pd.DataFrame = traindata.drop(['Success'], axis = 1)\n","y: pd.Series = traindata['Success']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSBYnWNnMW3M"},"outputs":[],"source":["for variable in categoricalFeatures:\n","  print(X[variable].value_counts())"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HfO_0WdnNcLg"},"outputs":[],"source":["for i, col in enumerate(metricFeatures):\n","  plt.figure(i)\n","  sns.boxplot(x=col, data=X)"]},{"cell_type":"markdown","metadata":{"id":"cr7VsbMUJ0An"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fillNa(data: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Fill missing values\n","\n","    Args:\n","        data (`pd.DataFrame`): Dataframe to be treated\n","\n","    Returns:\n","        `pd.DataFrame`: Treated dataframe\n","    \"\"\"    \n","\n","    # on all of these features, if a value were to be different than 0, then it would not be missing, eg units approved, if the student approved, the value wouldn't be missing\n","    ifNaThen0: tuple[str,...] = (\n","        \"N units credited 1st period\",\n","        \"N unscored units 1st period\",\n","        \"N units approved 1st period\",\n","        \"N units credited 2nd period\",\n","        \"N unscored units 2nd period\",\n","        \"N units approved 2nd period\"\n","    )\n","\n","    # these features are filled differently, basically incoherence checking, but filling the Na on 'N units approved 1st/2nd period' is needed beforehand, more info below\n","    checkAfterVars: list[list[str,str]] = [\n","        [\"N units taken 1st period\", \"N units approved 1st period\"],\n","        [\"N units taken 2nd period\", \"N units approved 2nd period\"]\n","    ] \n","\n","    for var in metricFeatures:\n","        if var == (checkAfterVars[0][0] or checkAfterVars[1][0]): \n","            continue # skip current iteration\n","        if var in ifNaThen0:\n","            data[var] = data[var].fillna(0) # fill the ifNaThen0 vars with well, 0s\n","        else:    \n","            data[var] = data[var].fillna(data[var].median()) # fill everything else with the median of the values of the feature\n","\n","    # here we use the n units taken features we skipped earlier, a student has to have taken at least the same number of courses as the number of courses they passed\n","    for varList in checkAfterVars:\n","        # search for Na values on N units taken and replace by the equivalent value on N units approved\n","        data.loc[data[varList[0]].isna(), varList[0]] = data[varList[1]]\n","        # search for values on N units taken that are smaller than the equivalent on N units approved, replace by the equivalent value on N units approved\n","        data.loc[data[varList[0]] < data[varList[1]], varList[0]] = data[varList[1]]\n","\n","    for var in boolFeatures:\n","        if var == \"Regularized Fees\":\n","            data[var] = data[var].fillna(1) # if nothing is said about the fees, we can assume they have been paid\n","        else:\n","            data[var] = data[var].fillna(0) # here is like the ifNaThen0 situation, if the values were to not be 0, they would have been declared\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def removeOutliers(dataX: pd.DataFrame, datay: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Removes outliers and fixes any negative number incoherences on the selected variables from the dataframe\n","\n","    Args:\n","        data (`pd.DataFrame`): Dataframe to be treated\n","\n","    Returns:\n","        `pd.DataFrame`: Treated dataframe\n","    \"\"\"    \n","\n","    toBeTreated: dict[str, dict[str, float | None]] = {\n","        \"Application order\": {\"lower\": 0, \"upper\": None},\n","        \"Previous qualification score\": {\"lower\": 0, \"upper\": None},\n","        \"Entry score\": {\"lower\": 0, \"upper\": None},\n","        \"Age at enrollment\": {\"lower\": 0, \"upper\": None},\n","        \"N units credited 1st period\": {\"lower\": 0, \"upper\": 15},\n","        \"N units taken 1st period\": {\"lower\": 0, \"upper\": 20},\n","        \"N scored units 1st period\": {\"lower\": 0, \"upper\": 25},\n","        \"N units approved 1st period\": {\"lower\": 0, \"upper\": 20},\n","        \"Average grade 1st period\": {\"lower\": 0, \"upper\": None},\n","        \"N unscored units 1st period\": {\"lower\": 0, \"upper\": None},\n","        \"N units credited 2nd period\": {\"lower\": 0, \"upper\": 14},\n","        \"N units taken 2nd period\": {\"lower\": 0, \"upper\": 15},\n","        \"N scored units 2nd period\": {\"lower\": 0, \"upper\": 25},\n","        \"N units approved 2nd period\": {\"lower\": 0, \"upper\": 15},\n","        \"Average grade 2nd period\": {\"lower\": 0, \"upper\": None},\n","        \"N unscored units 2nd period\": {\"lower\": 0, \"upper\": None},\n","        \"Social Popularity\": {\"lower\": 0, \"upper\": None},\n","    }\n","    \n","    for var in toBeTreated:\n","        if toBeTreated[var][\"lower\"] != None:\n","            toRemove: list = list(dataX.loc[dataX[var] < toBeTreated[var][\"lower\"], var].index)\n","        if toBeTreated[var][\"upper\"] != None:\n","            toRemove.extend(list(dataX.loc[dataX[var] > toBeTreated[var][\"upper\"], var].index))\n","        dataX.drop(toRemove, axis=0, inplace=True)\n","        datay.drop(toRemove, axis=0, inplace=True)\n","\n","    return dataX, datay"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1714615770380,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"5h98BSRq_py7","outputId":"a263394f-0915-4c1f-e2a3-30ae60348218"},"outputs":[],"source":["def groupValues(data: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"replace values on columns that have lots of different values that can be grouped together to reduce the total number of dummies created after\n","\n","    Args:\n","        data (`pd.DataFrame`): Dataframe to be treated\n","\n","    Returns:\n","        `pd.DataFrame`: Treated dataframe\n","    \"\"\"    \n","    \n","    for col in [\"Mother's qualification\",  \"Father's qualification\", \"Previous qualification\"]:\n","        data.replace(regex={col: {r\"(?i)^no school.*$\": '0',\n","                            r\"(?i)^[0-4][a-z]{2} grade.*$\": '1', \n","                            r\"(?i)^[5-9]th grade.*$\": '2', \n","                            r\"(?i)^1[0-2]th grade.*$\": '3', \n","                            r\"(?i)^incomplete bachelor.*$\": '4', \n","                            r\"(?i)^bachelor degree.*$\": '5',\n","                            r\"(?i)^post-grad.*$\": '6',\n","                            r\"(?i)^master degree.*$\": '7',\n","                            r\"(?i)^phd.*$\": '8',}}, inplace=True)\n","    \n","    for col in [\"Mother's occupation\", \"Father's occupation\"]:\n","        data.replace(to_replace={col: [\"Superior-level Professional\", \"Intermediate-level Professional\", \"Politician/CEO\", \"Teacher\", \"Information Technology Specialist\"]}, value=\"Professional Fields\", inplace=True)\n","        data.replace(to_replace={col: [\"Skilled construction workers\", \"Assembly Worker\", \"Factory worker\", \"Lab Technocian\"]}, value=\"Technical and Skilled Trades\", inplace=True)\n","        data.replace(to_replace={col: [\"Administrative Staff\", \"Office worker\", \"Accounting operator\"]}, value=\"White collar Jobs\", inplace=True)\n","        data.replace(to_replace={col: [\"Restaurant worker\", \"Personal care worker\", \"Seller\", \"Cleaning worker\"]}, value=\"Service Industry\", inplace=True)\n","        data.replace(to_replace={col: [\"Private Security\", \"Armed Forces\"]}, value=\"Security and Armed Forces\", inplace=True)\n","        data.replace(to_replace={col: [\"Unskilled Worker\", \"Other\", \"Student\", \"Artist\"]}, value=\"Recreational or unskilled\", inplace=True)\n","        data.replace(to_replace={col: [\"Engineer\", \"Scientist\", \"Health professional\"]}, value=\"STEM Jobs\", inplace=True)\n","\n","    data.replace(to_replace={\"Marital status\": {\"facto union\": \"married\",\n","                                \"legally separated\": \"divorced\",\n","                                # \"widower\": \"single\" reduces performance\n","                                }}, inplace=True)\n","    \n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def getDummies(train: pd.DataFrame, test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n","    \"\"\"get dummies, add 0s to columns that are in test but not in train, and vice-versa, reorder the columns so that they are in the same order\n","\n","    Args:\n","        train (`pd.DataFrame`): Train dataframe to be treated\n","        test (`pd.DataFrame`): Test dataframe to be treated\n","\n","    Returns:\n","        `tuple`[`pd.DataFrame`, `pd.DataFrame`]: treated train and test dataframes\n","    \"\"\"    \n","    \n","    train: pd.DataFrame = pd.get_dummies(data=train, prefix_sep=\"-\", dummy_na=True, drop_first=False)\n","    test: pd.DataFrame = pd.get_dummies(data=test, prefix_sep=\"-\", dummy_na=True, drop_first=False)\n","\n","    train[(list(set(test.columns) - set(train.columns)))] = 0\n","    test[(list(set(train.columns) - set(test.columns)))] = 0\n","\n","    test = test.reindex(columns=train.columns)\n","\n","    return train, test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def scaleData(train: pd.DataFrame, test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n","    \"\"\"Tranforms the values in the dataframes to fit in a scale of 0 to 1\n","\n","    Args:\n","        train (pd.DataFrame): Unscaled train dataframe\n","        test (pd.DataFrame): Unscaled test dataframe\n","\n","    Returns:\n","        tuple[pd.DataFrame, pd.DataFrame]: Both scaled dataframes\n","    \"\"\"    \n","\n","    scaler = MinMaxScaler()\n","    scaler.fit(train)\n","\n","    train = pd.DataFrame(scaler.transform(train), columns = train.columns, index = train.index)\n","    test = pd.DataFrame(scaler.transform(test), columns = test.columns, index = test.index)\n","\n","    return train, test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepData(X_train: pd.DataFrame, Y_train: pd.DataFrame, X_test: pd.DataFrame, Y_test: pd.DataFrame | None = None) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame | None]:\n","    \"\"\"Runs the preprocessing steps on the dataframes\n","\n","    Args:\n","        X_train (pd.DataFrame): Un-preprocessed X_train dataframe\n","        Y_train (pd.DataFrame): Un-preprocessed Y_train dataframe\n","        X_test (pd.DataFrame): Un-preprocessed X_test dataframe\n","        Y_test (pd.DataFrame | None, optional): Un-preprocessed Y_test dataframe, only needed for model assessment. Defaults to None.\n","\n","    Returns:\n","        tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame | None]: Treated dataframes\n","    \"\"\"    \n","    \n","    fillNa(X_train)\n","    fillNa(X_test)\n","    removeOutliers(X_train, Y_train)\n","    \n","    if type(Y_test) != type(None):\n","        removeOutliers(X_test, Y_test)\n","\n","    groupValues(X_train)\n","    groupValues(X_test)\n","    X_train, X_test = getDummies(X_train, X_test)\n","    # X_train, X_test = scaleData(X_train,X_test)\n","\n","    return X_train, Y_train, X_test, Y_test"]},{"cell_type":"markdown","metadata":{"id":"wEGylAQ9vdSp"},"source":["# Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Run a model to get the features with least importance, remove those that are not important\n","# model: RandomForestClassifier = RandomForestClassifier(936, n_jobs=cpuc)\n","# model.fit(X_train, y_train)\n","\n","# predictions = model.predict(testdata)\n","\n","# droplist = []\n","\n","# for x, y in zip(list(X.columns), model.feature_importances_):\n","#     if y*100 == 0:\n","#         print(f\"{x}: {y*100:.2f}\")\n","#         droplist.append(x)\n","\n","# X_train.drop(droplist, axis=1, inplace=True)\n","# X_val.drop(droplist, axis=1, inplace=True)\n","# testdata.drop(droplist, axis=1, inplace=True)\n","\n","# DROPPING THESE REDUCES MODEL SCORE"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def runGS(X_train: pd.DataFrame, Y_train: pd.DataFrame) -> dict:\n","    \"\"\"Runs a GridSearch with the parameter space defined within the function\n","\n","    Args:\n","        X (pd.DataFrame): Preprocessed X_train\n","        y (pd.DataFrame): Preprocessed X_train\n","\n","    Returns:\n","        dict: Best parameters for the model\n","    \"\"\"\n","    \n","    model = RandomForestClassifier(n_jobs=cpuc)\n","    model.fit(X_train,Y_train)\n","    parameter_space: dict[str] = {\n","        \"n_estimators\": tuple(range(100,1000,10)),\n","        \"max_depth\": [None, *range(10,101,10)],\n","        \"min_samples_split\": tuple(range(2,7)),\n","        \"min_samples_leaf\": tuple(range(1,6)),\n","        \"max_features\": [\"sqrt\", \"log2\"],\n","        \"ccp_alpha\": tuple(map(lambda x: x/100, range(0, 6)))\n","        }\n","\n","    gs = GridSearchCV(model, parameter_space, scoring = 'f1_weighted', cv = 10, verbose=1, n_jobs=cpuc)\n","    gs.fit(X_train,Y_train)\n","\n","    return(gs.best_params_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def runModel(X_train: pd.DataFrame, Y_train: pd.DataFrame, X_test: pd.DataFrame, Y_test: pd.DataFrame | None = None) -> str | np.ndarray:\n","    \"\"\"Runs the model to get predictions or a classification report\n","\n","    Args:\n","        X_train (pd.DataFrame): X_train dataframe\n","        Y_train (pd.DataFrame): Y_train dataframe\n","        X_test (pd.DataFrame): X_test dataframe\n","        Y_test (pd.DataFrame | None, optional): Y_test dataframe, only needed for model assessment. Defaults to None.\n","\n","    Returns:\n","        str: Classification report, used to assess model performance\n","        np.ndarray: Predictions, used to create the output file to upload to kaggle\n","    \"\"\"    \n","    \n","    model: RandomForestClassifier = RandomForestClassifier(936, n_jobs=cpuc, random_state=15)\n","    model.fit(X_train, Y_train)\n","\n","    predictions = model.predict(X_test)\n","\n","    if type(Y_test) != type(None):\n","        predictions = classification_report(Y_test, predictions)\n","    \n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def runAll(X_train: pd.DataFrame, Y_train: pd.DataFrame, X_test: pd.DataFrame, split: bool = False) -> None:\n","    \"\"\"Runs the algorithm\n","\n","    Args:\n","        X_train (pd.DataFrame): Raw/Un-preprocessed X_train dataframe\n","        Y_train (pd.DataFrame): Raw/Un-preprocessed Y_train dataframe\n","        X_test (pd.DataFrame): Raw/Un-preprocessed X_test dataframe\n","        split (bool, optional): Whether or not to split the dataframes using train_test_split, used for model assessment. Defaults to False.\n","    \"\"\"\n","    \n","    if split == True:\n","        X_train, X_test, Y_train, Y_test = train_test_split(X,y, test_size=0.2, random_state=15)\n","        X_train, Y_train, X_test, Y_test = prepData(X_train, Y_train, X_test, Y_test)\n","        print(runModel(X_train, Y_train, X_test, Y_test))\n","    else:\n","        X_train, Y_train, X_test, Y_test = prepData(X_train, Y_train, X_test)\n","        predictions = runModel(X_train, Y_train, X_test)\n","        outputData: pd.DataFrame = pd.DataFrame([X_test.index, predictions]).T\n","        outputData.columns = [\"Userid\", \"Success\"]\n","        outputData.set_index('Userid').to_csv(\"./answer.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["runAll(X, y, testdata, split=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment if you feel like using your computer as a heater (2970000 fits)\n","# runGS((oUse := prepData(X,y,testdata))[0],oUse[1])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMoSHPLWBcU0IMAuXgVVj+p","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
