{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5036,"status":"ok","timestamp":1714605412179,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"0LXrrC_9q3an","outputId":"7aafad20-fbe3-41a6-bc1f-fd2bc68ab753"},"outputs":[],"source":["# Run if using on google collab, change path accordingly\n","from google.colab import drive\n","drive.mount('/content/drive', force_remount=True)\n","path = '/content/drive/MyDrive/[02] School/[01] University/[02] Bachelor\\'s Year 2/[02] Spring Semester/[04] Machine Learning/Colab Notebooks/ML - LGI/mlproj/'"]},{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[],"source":["# run if running locally\n","path = ''"]},{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":30432,"status":"ok","timestamp":1714605442603,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"N5misv8iqv_c","outputId":"5699d9a9-5954-4488-d8c4-c1efca8474bb"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.model_selection import train_test_split, GridSearchCV\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import classification_report\n","import multiprocessing\n","\n","cpuc = multiprocessing.cpu_count()-1\n","\n","#setting seaborn visual style in plt\n","sns.set_theme()"]},{"cell_type":"markdown","metadata":{"id":"7rYg5St0J3ap"},"source":["# Integration & Exploration"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Duplicaded: 1645\n","Missing: 10469\n","Non-Registered (empty): 100\n"]}],"source":["traindata: pd.DataFrame = pd.read_csv(path + 'data/train.csv').set_index('Userid')\n","print(f\"Duplicaded: {traindata.duplicated().sum()}\\nMissing: {traindata.isna().sum().sum()}\\nNon-Registered (empty): {(traindata[\"Registered\"] != \"Yes\").sum()}\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# import the data and drop remove useless stuff\n","traindata: pd.DataFrame = traindata.drop('Observations', axis=1).drop_duplicates()\n","testdata: pd.DataFrame = pd.read_csv(path + 'project_data/test.csv').set_index('Userid').drop(['Registered', 'Observations'], axis=1)\n","\n","traindata = traindata[traindata['Registered'] == 'Yes']\n","traindata = traindata.drop('Registered', axis=1)"]},{"cell_type":"code","execution_count":5,"metadata":{"executionInfo":{"elapsed":243,"status":"ok","timestamp":1714606527362,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"kGMkB5Dax7jH"},"outputs":[],"source":["metricFeatures: list[str] = ['Application order','Previous qualification score','Entry score','Age at enrollment','N units credited 1st period',\n","       'N units taken 1st period', 'N scored units 1st period',\n","       'N units approved 1st period', 'Average grade 1st period',\n","       'N unscored units 1st period', 'N units credited 2nd period',\n","       'N units taken 2nd period', 'N scored units 2nd period',\n","       'N units approved 2nd period', 'Average grade 2nd period',\n","       'N unscored units 2nd period','Social Popularity']\n","categoricalFeatures: list[str] =  ['Application mode','Marital status','Course','Previous qualification','Nationality',\"Mother's qualification\",\n","       \"Father's qualification\",\"Mother's occupation\",\"Father's occupation\"]\n","boolFeatures: list[str] = ['Morning shift participation','Displaced','Special needs','Debtor','Regularized Fees','Gender_Male','External Funding','International']"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["traindata[metricFeatures].describe()"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":378,"status":"ok","timestamp":1714615768947,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"0x4hZRPq-PCx"},"outputs":[],"source":["X: pd.DataFrame = traindata.drop(['Success'], axis = 1)\n","y: pd.Series = traindata['Success']"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"pSBYnWNnMW3M"},"outputs":[],"source":["for variable in categoricalFeatures:\n","  print(X[variable].value_counts())"]},{"cell_type":"code","execution_count":7,"metadata":{"id":"HfO_0WdnNcLg"},"outputs":[{"ename":"ValueError","evalue":"cannot reindex on an axis with duplicate labels","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[1;32mIn[7], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, col \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(metricFeatures):\n\u001b[0;32m      2\u001b[0m   plt\u001b[38;5;241m.\u001b[39mfigure(i)\n\u001b[1;32m----> 3\u001b[0m   \u001b[43msns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mboxplot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcol\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtraindata\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\seaborn\\categorical.py:1634\u001b[0m, in \u001b[0;36mboxplot\u001b[1;34m(data, x, y, hue, order, hue_order, orient, color, palette, saturation, fill, dodge, width, gap, whis, linecolor, linewidth, fliersize, hue_norm, native_scale, log_scale, formatter, legend, ax, **kwargs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m color \u001b[38;5;241m=\u001b[39m _default_color(\n\u001b[0;32m   1628\u001b[0m     ax\u001b[38;5;241m.\u001b[39mfill_between, hue, color,\n\u001b[0;32m   1629\u001b[0m     {k: v \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mitems() \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolor\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfc\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfacecolor\u001b[39m\u001b[38;5;124m\"\u001b[39m]},\n\u001b[0;32m   1630\u001b[0m     saturation\u001b[38;5;241m=\u001b[39msaturation,\n\u001b[0;32m   1631\u001b[0m )\n\u001b[0;32m   1632\u001b[0m linecolor \u001b[38;5;241m=\u001b[39m p\u001b[38;5;241m.\u001b[39m_complement_color(linecolor, color, p\u001b[38;5;241m.\u001b[39m_hue_map)\n\u001b[1;32m-> 1634\u001b[0m \u001b[43mp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mplot_boxes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1635\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1636\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdodge\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdodge\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgap\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mgap\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1638\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfill\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1639\u001b[0m \u001b[43m    \u001b[49m\u001b[43mwhis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwhis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1640\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1641\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinecolor\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinecolor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1642\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlinewidth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlinewidth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1643\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfliersize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfliersize\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1644\u001b[0m \u001b[43m    \u001b[49m\u001b[43mplot_kws\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1645\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1647\u001b[0m p\u001b[38;5;241m.\u001b[39m_add_axis_labels(ax)\n\u001b[0;32m   1648\u001b[0m p\u001b[38;5;241m.\u001b[39m_adjust_cat_axis(ax, axis\u001b[38;5;241m=\u001b[39mp\u001b[38;5;241m.\u001b[39morient)\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\seaborn\\categorical.py:631\u001b[0m, in \u001b[0;36m_CategoricalPlotter.plot_boxes\u001b[1;34m(self, width, dodge, gap, fill, whis, color, linecolor, linewidth, fliersize, plot_kws)\u001b[0m\n\u001b[0;32m    627\u001b[0m props[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mflier\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39msetdefault(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmarkersize\u001b[39m\u001b[38;5;124m\"\u001b[39m, fliersize)\n\u001b[0;32m    629\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39max\n\u001b[1;32m--> 631\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msub_vars\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msub_data\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miter_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43miter_vars\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    632\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mfrom_comp_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    633\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mallow_empty\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    635\u001b[0m \u001b[43m    \u001b[49m\u001b[43max\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_axes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msub_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    637\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrouped\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msub_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupby\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43morient\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[43mvalue_var\u001b[49m\u001b[43m]\u001b[49m\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\seaborn\\_base.py:902\u001b[0m, in \u001b[0;36mVectorPlotter.iter_data\u001b[1;34m(self, grouping_vars, reverse, from_comp_data, by_facet, allow_empty, dropna)\u001b[0m\n\u001b[0;32m    899\u001b[0m grouping_vars \u001b[38;5;241m=\u001b[39m [var \u001b[38;5;28;01mfor\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m grouping_vars \u001b[38;5;28;01mif\u001b[39;00m var \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvariables]\n\u001b[0;32m    901\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m from_comp_data:\n\u001b[1;32m--> 902\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcomp_data\u001b[49m\n\u001b[0;32m    903\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    904\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mplot_data\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\seaborn\\_base.py:1007\u001b[0m, in \u001b[0;36mVectorPlotter.comp_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1005\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1006\u001b[0m             comp_col \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mSeries(dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mfloat\u001b[39m, name\u001b[38;5;241m=\u001b[39mvar)\n\u001b[1;32m-> 1007\u001b[0m         \u001b[43mcomp_data\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minsert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcomp_col\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1009\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_comp_data \u001b[38;5;241m=\u001b[39m comp_data\n\u001b[0;32m   1011\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_comp_data\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5171\u001b[0m, in \u001b[0;36mDataFrame.insert\u001b[1;34m(self, loc, column, value, allow_duplicates)\u001b[0m\n\u001b[0;32m   5168\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, DataFrame):\n\u001b[0;32m   5169\u001b[0m     value \u001b[38;5;241m=\u001b[39m value\u001b[38;5;241m.\u001b[39miloc[:, \u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m-> 5171\u001b[0m value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5172\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mgr\u001b[38;5;241m.\u001b[39minsert(loc, column, value, refs\u001b[38;5;241m=\u001b[39mrefs)\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:5263\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5261\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, Series):\n\u001b[0;32m   5262\u001b[0m         value \u001b[38;5;241m=\u001b[39m Series(value)\n\u001b[1;32m-> 5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_reindex_for_setitem\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[0;32m   5266\u001b[0m     com\u001b[38;5;241m.\u001b[39mrequire_length_match(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:12692\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12689\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[0;32m  12690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12691\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n\u001b[1;32m> 12692\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[0;32m  12694\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[0;32m  12695\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincompatible index of inserted column with frame index\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m  12696\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m  12697\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m reindexed_value, \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\frame.py:12687\u001b[0m, in \u001b[0;36m_reindex_for_setitem\u001b[1;34m(value, index)\u001b[0m\n\u001b[0;32m  12685\u001b[0m \u001b[38;5;66;03m# GH#4107\u001b[39;00m\n\u001b[0;32m  12686\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m> 12687\u001b[0m     reindexed_value \u001b[38;5;241m=\u001b[39m \u001b[43mvalue\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m_values\n\u001b[0;32m  12688\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n\u001b[0;32m  12689\u001b[0m     \u001b[38;5;66;03m# raised in MultiIndex.from_tuples, see test_insert_error_msmgs\u001b[39;00m\n\u001b[0;32m  12690\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\u001b[38;5;241m.\u001b[39mindex\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m  12691\u001b[0m         \u001b[38;5;66;03m# duplicate axis\u001b[39;00m\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\series.py:5153\u001b[0m, in \u001b[0;36mSeries.reindex\u001b[1;34m(self, index, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5136\u001b[0m \u001b[38;5;129m@doc\u001b[39m(\n\u001b[0;32m   5137\u001b[0m     NDFrame\u001b[38;5;241m.\u001b[39mreindex,  \u001b[38;5;66;03m# type: ignore[has-type]\u001b[39;00m\n\u001b[0;32m   5138\u001b[0m     klass\u001b[38;5;241m=\u001b[39m_shared_doc_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mklass\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5151\u001b[0m     tolerance\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   5152\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Series:\n\u001b[1;32m-> 5153\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5154\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5155\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5156\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5157\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5158\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5159\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5160\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   5161\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:5610\u001b[0m, in \u001b[0;36mNDFrame.reindex\u001b[1;34m(self, labels, index, columns, axis, method, copy, level, fill_value, limit, tolerance)\u001b[0m\n\u001b[0;32m   5607\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reindex_multi(axes, copy, fill_value)\n\u001b[0;32m   5609\u001b[0m \u001b[38;5;66;03m# perform the reindex on the axes\u001b[39;00m\n\u001b[1;32m-> 5610\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_reindex_axes\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5611\u001b[0m \u001b[43m    \u001b[49m\u001b[43maxes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\n\u001b[0;32m   5612\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m, method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreindex\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\generic.py:5633\u001b[0m, in \u001b[0;36mNDFrame._reindex_axes\u001b[1;34m(self, axes, level, limit, tolerance, method, fill_value, copy)\u001b[0m\n\u001b[0;32m   5630\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[0;32m   5632\u001b[0m ax \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis(a)\n\u001b[1;32m-> 5633\u001b[0m new_index, indexer \u001b[38;5;241m=\u001b[39m \u001b[43max\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreindex\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   5634\u001b[0m \u001b[43m    \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlimit\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlimit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtolerance\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtolerance\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   5635\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5637\u001b[0m axis \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_axis_number(a)\n\u001b[0;32m   5638\u001b[0m obj \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_reindex_with_indexers(\n\u001b[0;32m   5639\u001b[0m     {axis: [new_index, indexer]},\n\u001b[0;32m   5640\u001b[0m     fill_value\u001b[38;5;241m=\u001b[39mfill_value,\n\u001b[0;32m   5641\u001b[0m     copy\u001b[38;5;241m=\u001b[39mcopy,\n\u001b[0;32m   5642\u001b[0m     allow_dups\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[0;32m   5643\u001b[0m )\n","File \u001b[1;32me:\\GitHub\\mlproj\\.venv\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:4429\u001b[0m, in \u001b[0;36mIndex.reindex\u001b[1;34m(self, target, method, level, limit, tolerance)\u001b[0m\n\u001b[0;32m   4426\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot handle a non-unique multi-index!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4427\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mis_unique:\n\u001b[0;32m   4428\u001b[0m     \u001b[38;5;66;03m# GH#42568\u001b[39;00m\n\u001b[1;32m-> 4429\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcannot reindex on an axis with duplicate labels\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   4430\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4431\u001b[0m     indexer, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_indexer_non_unique(target)\n","\u001b[1;31mValueError\u001b[0m: cannot reindex on an axis with duplicate labels"]},{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 1 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["for i, col in enumerate(metricFeatures):\n","  plt.figure(i)\n","  sns.boxplot(x=col, data=traindata)"]},{"cell_type":"markdown","metadata":{"id":"cr7VsbMUJ0An"},"source":["# Preprocessing"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def fillNa(data: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Fill missing values\n","\n","    Args:\n","        data (`pd.DataFrame`): Dataframe to be treated\n","\n","    Returns:\n","        `pd.DataFrame`: Treated dataframe\n","    \"\"\"    \n","\n","    # on all of these features, if a value were to be different than 0, then it would not be missing, eg units approved, if the student approved, the value wouldn't be missing\n","    ifNaThen0: tuple[str,...] = (\n","        \"N units credited 1st period\",\n","        \"N unscored units 1st period\",\n","        \"N units approved 1st period\",\n","        \"N units credited 2nd period\",\n","        \"N unscored units 2nd period\",\n","        \"N units approved 2nd period\"\n","    )\n","\n","    # these features are filled differently, basically incoherence checking, but filling the Na on 'N units approved 1st/2nd period' is needed beforehand, more info below\n","    checkAfterVars: list[list[str,str]] = [\n","        [\"N units taken 1st period\", \"N units approved 1st period\"],\n","        [\"N units taken 2nd period\", \"N units approved 2nd period\"]\n","    ] \n","\n","    for var in metricFeatures:\n","        if var == (checkAfterVars[0][0] or checkAfterVars[1][0]): \n","            continue # skip current iteration\n","        if var in ifNaThen0:\n","            data[var] = data[var].fillna(0) # fill the ifNaThen0 vars with well, 0s\n","        else:    \n","            data[var] = data[var].fillna(data[var].median()) # fill everything else with the median of the values of the feature\n","\n","    # here we use the n units taken features we skipped earlier, a student has to have taken at least the same number of courses as the number of courses they passed\n","    for varList in checkAfterVars:\n","        # search for Na values on N units taken and replace by the equivalent value on N units approved\n","        data.loc[data[varList[0]].isna(), varList[0]] = data[varList[1]]\n","        # search for values on N units taken that are smaller than the equivalent on N units approved, replace by the equivalent value on N units approved\n","        data.loc[data[varList[0]] < data[varList[1]], varList[0]] = data[varList[1]]\n","\n","    for var in boolFeatures:\n","        if var == \"Regularized Fees\":\n","            data[var] = data[var].fillna(1) # if nothing is said about the fees, we can assume they have been paid\n","        else:\n","            data[var] = data[var].fillna(0) # here is like the ifNaThen0 situation, if the values were to not be 0, they would have been declared\n","\n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def removeOutliers(dataX: pd.DataFrame, datay: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"Removes outliers and fixes any negative number incoherences on the selected variables from the dataframe\n","\n","    Args:\n","        data (`pd.DataFrame`): Dataframe to be treated\n","\n","    Returns:\n","        `pd.DataFrame`: Treated dataframe\n","    \"\"\"    \n","\n","    toBeTreated: dict[str, dict[str, float | None]] = {\n","        \"Application order\": {\"lower\": 0, \"upper\": None},\n","        \"Previous qualification score\": {\"lower\": 0, \"upper\": None},\n","        \"Entry score\": {\"lower\": 0, \"upper\": None},\n","        \"Age at enrollment\": {\"lower\": 0, \"upper\": None},\n","        \"N units credited 1st period\": {\"lower\": 0, \"upper\": 15},\n","        \"N units taken 1st period\": {\"lower\": 0, \"upper\": 20},\n","        \"N scored units 1st period\": {\"lower\": 0, \"upper\": 25},\n","        \"N units approved 1st period\": {\"lower\": 0, \"upper\": 20},\n","        \"Average grade 1st period\": {\"lower\": 0, \"upper\": None},\n","        \"N unscored units 1st period\": {\"lower\": 0, \"upper\": None},\n","        \"N units credited 2nd period\": {\"lower\": 0, \"upper\": 14},\n","        \"N units taken 2nd period\": {\"lower\": 0, \"upper\": 15},\n","        \"N scored units 2nd period\": {\"lower\": 0, \"upper\": 25},\n","        \"N units approved 2nd period\": {\"lower\": 0, \"upper\": 15},\n","        \"Average grade 2nd period\": {\"lower\": 0, \"upper\": None},\n","        \"N unscored units 2nd period\": {\"lower\": 0, \"upper\": None},\n","        \"Social Popularity\": {\"lower\": 0, \"upper\": None},\n","    }\n","    \n","    for var in toBeTreated:\n","        if toBeTreated[var][\"lower\"] != None:\n","            toRemove: list = list(dataX.loc[dataX[var] < toBeTreated[var][\"lower\"], var].index)\n","        if toBeTreated[var][\"upper\"] != None:\n","            toRemove.extend(list(dataX.loc[dataX[var] > toBeTreated[var][\"upper\"], var].index))\n","        dataX.drop(toRemove, axis=0, inplace=True)\n","        datay.drop(toRemove, axis=0, inplace=True)\n","\n","    return dataX, datay"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":649},"executionInfo":{"elapsed":388,"status":"ok","timestamp":1714615770380,"user":{"displayName":"Diogo Carvalho","userId":"00840682249166754442"},"user_tz":-60},"id":"5h98BSRq_py7","outputId":"a263394f-0915-4c1f-e2a3-30ae60348218"},"outputs":[],"source":["def groupValues(data: pd.DataFrame) -> pd.DataFrame:\n","    \"\"\"replace values on columns that have lots of different values that can be grouped together to reduce the total number of dummies created after\n","\n","    Args:\n","        data (`pd.DataFrame`): Dataframe to be treated\n","\n","    Returns:\n","        `pd.DataFrame`: Treated dataframe\n","    \"\"\"    \n","    \n","    for col in [\"Mother's qualification\",  \"Father's qualification\", \"Previous qualification\"]:\n","        data.replace(regex={col: {r\"(?i)^no school.*$\": '0',\n","                            r\"(?i)^[0-4][a-z]{2} grade.*$\": '1', \n","                            r\"(?i)^[5-9]th grade.*$\": '2', \n","                            r\"(?i)^1[0-2]th grade.*$\": '3', \n","                            r\"(?i)^incomplete bachelor.*$\": '4', \n","                            r\"(?i)^bachelor degree.*$\": '5',\n","                            r\"(?i)^post-grad.*$\": '6',\n","                            r\"(?i)^master degree.*$\": '7',\n","                            r\"(?i)^phd.*$\": '8',}}, inplace=True)\n","    \n","    for col in [\"Mother's occupation\", \"Father's occupation\"]:\n","        data.replace(to_replace={col: [\"Superior-level Professional\", \"Intermediate-level Professional\", \"Politician/CEO\", \"Teacher\", \"Information Technology Specialist\"]}, value=\"Professional Fields\", inplace=True)\n","        data.replace(to_replace={col: [\"Skilled construction workers\", \"Assembly Worker\", \"Factory worker\", \"Lab Technocian\"]}, value=\"Technical and Skilled Trades\", inplace=True)\n","        data.replace(to_replace={col: [\"Administrative Staff\", \"Office worker\", \"Accounting operator\"]}, value=\"White collar Jobs\", inplace=True)\n","        data.replace(to_replace={col: [\"Restaurant worker\", \"Personal care worker\", \"Seller\", \"Cleaning worker\"]}, value=\"Service Industry\", inplace=True)\n","        data.replace(to_replace={col: [\"Private Security\", \"Armed Forces\"]}, value=\"Security and Armed Forces\", inplace=True)\n","        data.replace(to_replace={col: [\"Unskilled Worker\", \"Other\", \"Student\", \"Artist\"]}, value=\"Recreational or unskilled\", inplace=True)\n","        data.replace(to_replace={col: [\"Engineer\", \"Scientist\", \"Health professional\"]}, value=\"STEM Jobs\", inplace=True)\n","\n","    data.replace(to_replace={\"Marital status\": {\"facto union\": \"married\",\n","                                \"legally separated\": \"divorced\",\n","                                # \"widower\": \"single\" reduces performance\n","                                }}, inplace=True)\n","    \n","    return data"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def getDummies(train: pd.DataFrame, test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n","    \"\"\"get dummies, add 0s to columns that are in test but not in train, and vice-versa, reorder the columns so that they are in the same order\n","\n","    Args:\n","        train (`pd.DataFrame`): Train dataframe to be treated\n","        test (`pd.DataFrame`): Test dataframe to be treated\n","\n","    Returns:\n","        `tuple`[`pd.DataFrame`, `pd.DataFrame`]: treated train and test dataframes\n","    \"\"\"    \n","    \n","    train: pd.DataFrame = pd.get_dummies(data=train, prefix_sep=\"-\", dummy_na=True, drop_first=False)\n","    test: pd.DataFrame = pd.get_dummies(data=test, prefix_sep=\"-\", dummy_na=True, drop_first=False)\n","\n","    train[(list(set(test.columns) - set(train.columns)))] = 0\n","    test[(list(set(train.columns) - set(test.columns)))] = 0\n","\n","    test = test.reindex(columns=train.columns)\n","\n","    return train, test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def scaleData(train: pd.DataFrame, test: pd.DataFrame) -> tuple[pd.DataFrame, pd.DataFrame]:\n","    \"\"\"Tranforms the values in the dataframes to fit in a scale of 0 to 1\n","\n","    Args:\n","        train (pd.DataFrame): Unscaled train dataframe\n","        test (pd.DataFrame): Unscaled test dataframe\n","\n","    Returns:\n","        tuple[pd.DataFrame, pd.DataFrame]: Both scaled dataframes\n","    \"\"\"    \n","\n","    scaler = MinMaxScaler()\n","    scaler.fit(train)\n","\n","    train = pd.DataFrame(scaler.transform(train), columns = train.columns, index = train.index)\n","    test = pd.DataFrame(scaler.transform(test), columns = test.columns, index = test.index)\n","\n","    return train, test"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def prepData(X_train: pd.DataFrame, Y_train: pd.DataFrame, X_test: pd.DataFrame, Y_test: pd.DataFrame | None = None) -> tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame | None]:\n","    \"\"\"Runs the preprocessing steps on the dataframes\n","\n","    Args:\n","        X_train (pd.DataFrame): Un-preprocessed X_train dataframe\n","        Y_train (pd.DataFrame): Un-preprocessed Y_train dataframe\n","        X_test (pd.DataFrame): Un-preprocessed X_test dataframe\n","        Y_test (pd.DataFrame | None, optional): Un-preprocessed Y_test dataframe, only needed for model assessment. Defaults to None.\n","\n","    Returns:\n","        tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame, pd.DataFrame | None]: Treated dataframes\n","    \"\"\"    \n","    \n","    fillNa(X_train)\n","    fillNa(X_test)\n","    removeOutliers(X_train, Y_train)\n","    \n","    if type(Y_test) != type(None):\n","        removeOutliers(X_test, Y_test)\n","\n","    groupValues(X_train)\n","    groupValues(X_test)\n","    X_train, X_test = getDummies(X_train, X_test)\n","    # X_train, X_test = scaleData(X_train,X_test)\n","\n","    return X_train, Y_train, X_test, Y_test"]},{"cell_type":"markdown","metadata":{"id":"wEGylAQ9vdSp"},"source":["# Feature Selection"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# # Run a model to get the features with least importance, remove those that are not important\n","# model: RandomForestClassifier = RandomForestClassifier(970, n_jobs=cpuc)\n","# model.fit(X_train, y_train)\n","\n","# predictions = model.predict(testdata)\n","\n","# droplist = []\n","\n","# for x, y in zip(list(X.columns), model.feature_importances_):\n","#     if y*100 == 0:\n","#         print(f\"{x}: {y*100:.2f}\")\n","#         droplist.append(x)\n","\n","# X_train.drop(droplist, axis=1, inplace=True)\n","# X_val.drop(droplist, axis=1, inplace=True)\n","# testdata.drop(droplist, axis=1, inplace=True)\n","\n","# DROPPING THESE REDUCES MODEL SCORE"]},{"cell_type":"markdown","metadata":{},"source":["# Model"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def runGS(X_train: pd.DataFrame, Y_train: pd.DataFrame) -> dict:\n","    \"\"\"Runs a GridSearch with the parameter space defined within the function\n","\n","    Args:\n","        X (pd.DataFrame): Preprocessed X_train\n","        y (pd.DataFrame): Preprocessed X_train\n","\n","    Returns:\n","        dict: Best parameters for the model\n","    \"\"\"\n","    \n","    model = RandomForestClassifier(n_jobs=cpuc)\n","    model.fit(X_train,Y_train)\n","    parameter_space: dict[str] = {\n","        \"n_estimators\": tuple(range(100,1000,10)),\n","        \"max_depth\": [None, *range(10,101,10)],\n","        \"min_samples_split\": tuple(range(2,7)),\n","        \"min_samples_leaf\": tuple(range(1,6)),\n","        # \"max_features\": [\"sqrt\", \"log2\"],\n","        # \"ccp_alpha\": tuple(map(lambda x: x/100, range(0, 6)))\n","        }\n","\n","    gs = GridSearchCV(model, parameter_space, scoring = 'f1_weighted', cv = 10, verbose=1, n_jobs=cpuc)\n","    gs.fit(X_train,Y_train)\n","\n","    return(gs.best_params_)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def runModel(X_train: pd.DataFrame, Y_train: pd.DataFrame, X_test: pd.DataFrame, Y_test: pd.DataFrame | None = None) -> str | np.ndarray:\n","    \"\"\"Runs the model to get predictions or a classification report\n","\n","    Args:\n","        X_train (pd.DataFrame): X_train dataframe\n","        Y_train (pd.DataFrame): Y_train dataframe\n","        X_test (pd.DataFrame): X_test dataframe\n","        Y_test (pd.DataFrame | None, optional): Y_test dataframe, only needed for model assessment. Defaults to None.\n","\n","    Returns:\n","        str: Classification report, used to assess model performance\n","        np.ndarray: Predictions, used to create the output file to upload to kaggle\n","    \"\"\"    \n","    \n","    model: RandomForestClassifier = RandomForestClassifier(n_estimators=936, n_jobs=cpuc)\n","    model.fit(X_train, Y_train)\n","\n","    predictions = model.predict(X_test)\n","\n","    if type(Y_test) != type(None):\n","        predictions = classification_report(Y_test, predictions)\n","    \n","    return predictions"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def runAll(X_train: pd.DataFrame, Y_train: pd.DataFrame, X_test: pd.DataFrame, split: bool = False) -> None:\n","    \"\"\"Runs the algorithm\n","\n","    Args:\n","        X_train (pd.DataFrame): Raw/Un-preprocessed X_train dataframe\n","        Y_train (pd.DataFrame): Raw/Un-preprocessed Y_train dataframe\n","        X_test (pd.DataFrame): Raw/Un-preprocessed X_test dataframe\n","        split (bool, optional): Whether or not to split the dataframes using train_test_split, used for model assessment. Defaults to False.\n","    \"\"\"\n","    \n","    if split == True:\n","        X_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\n","        X_train, Y_train, X_test, Y_test = prepData(X_train, Y_train, X_test, Y_test)\n","        print(runModel(X_train, Y_train, X_test, Y_test))\n","    else:\n","        X_train, Y_train, X_test, Y_test = prepData(X_train, Y_train, X_test)\n","        predictions = runModel(X_train, Y_train, X_test)\n","        outputData: pd.DataFrame = pd.DataFrame([X_test.index, predictions]).T\n","        outputData.columns = [\"Userid\", \"Success\"]\n","        outputData.set_index('Userid').to_csv(\"./answer.csv\")"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["runAll(X, y, testdata, split=False)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# Uncomment if you feel like using your computer as a heater\n","# runGS((oUse := prepData(X,y,testdata))[0],oUse[1])"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyMoSHPLWBcU0IMAuXgVVj+p","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.3"}},"nbformat":4,"nbformat_minor":0}
